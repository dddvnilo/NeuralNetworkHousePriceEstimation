{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403c29be",
   "metadata": {},
   "source": [
    "# Procena cene kuća pomoću nerunonske mreže"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b54f10",
   "metadata": {},
   "source": [
    "## Opis problema i cilj projekta\n",
    "Cilj ovog projekta je razviti regresioni model zasnovan na neuronskoj mreži koji može precizno da proceni cenu kuća na osnovu njihovih karakteristika (poput kvadrature, broja soba, godine izgradnje…).  \n",
    "Ciljno obeležje je `SalePrice`, odnosno prodajna cena izražena u američkim dolarima (USD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c069c",
   "metadata": {},
   "source": [
    "## Faze izrade modela\n",
    "\n",
    "Proces rešavanja problema procene cena kuća obuhvata sledeće faze:\n",
    "\n",
    "1. **Priprema podataka**\n",
    "   - Učitavanje skupa podataka (`Ames Housing Dataset`).\n",
    "   - Uklanjanje kolona i zapisa sa previše nedostajućih vrednosti.\n",
    "   - Imputacija nedostajućih vrednosti: numeričke zamenjene medijanom, a kategorijske vrednosti su zamenjene specijalnom oznakom ('Missing') pre nego što su enkodirane u numerički oblik.\n",
    "   - Kodiranje kategorijskih atributa u numeričke vrednosti (one-hot encoding).\n",
    "   - Analiza korelacije atributa sa ciljnim obeležjem (`SalePrice`) i uklanjanje nerelevantnih atributa.\n",
    "\n",
    "2. **Smanjenje dimenzionalnosti**\n",
    "   - Primena PCA (Principal Component Analysis) kako bi se redukovala dimenzionalnost i transformisali atributi u nove komponente uz očuvanje varijanse.\n",
    "\n",
    "3. **Podela podataka**\n",
    "   - Deljenje podataka na trening, validacioni i test skup (70:15:15).\n",
    "\n",
    "4. **Treniranje modela**\n",
    "   - Izgradnja i treniranje neuronske mreže za regresiju.\n",
    "   - Korišćenje MSE (Mean Squared Error) funkcije gubitka i Adam optimizatora.\n",
    "   - Pratimo performanse na validacionom skupu i primenjujemo early stopping.\n",
    "\n",
    "5. **Evaluacija i testiranje**\n",
    "   - Ocena modela na test skupu (MSE, RMSE, MAE, R2).\n",
    "   - Vizuelizacija grešaka i poređenje predviđenih i stvarnih cena kuća.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020142fe",
   "metadata": {},
   "source": [
    "## Koraci u razvoju modela\n",
    "\n",
    "#### 1. Učitavanje skupa podataka\n",
    "Koristimo `pandas.read_csv()` da učitamo dataset `AmesHousing.csv`.\n",
    "\n",
    "#### 2. Uklanjanje kolona sa previše nedostajućih vrednosti\n",
    "Funkcija `drop_high_missing(df, threshold)` uklanja sve kolone u kojima je više od `threshold` (30%) vrednosti **NaN**.  \n",
    "Ovo smanjuje uticaj nepotpunih podataka na model.\n",
    "\n",
    "#### 3. Uklanjanje atributa sa slabom korelacijom sa ciljem\n",
    "Funkcija `remove_low_correlation_features(df, target_col, threshold)` uklanja numeričke kolone čija **apsolutna korelacija** sa ciljnim obeležjem (`SalePrice`) je manja od zadate vrednosti (`threshold`, npr. 0.05).\n",
    "\n",
    "- Zadržavamo samo relevantne atribute koji su statistički povezani sa cenom.\n",
    "- Funkcija takođe generiše vizualni prikaz zadržanih i uklonjenih atributa (grafik sa barovima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b8ec7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shape: (2930, 82)\n",
      "Dropping 6 columns with >30% missing values.\n",
      "After dropping columns: (2930, 76)\n",
      "Removing 8 features with correlation < 0.05\n",
      "After removing low-correlation features: (2930, 68)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from data.preprocessing import (\n",
    "    drop_high_missing,\n",
    "    remove_low_correlation_features\n",
    ")\n",
    "data_path = \"dataset/AmesHousing.csv\"\n",
    "drop_missing_thresh = 0.30\n",
    "correlation_thresh = 0.05\n",
    "target = \"SalePrice\"\n",
    "output_dir = \"output\"\n",
    "\n",
    "# 1) Load data\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Loaded dataset shape:\", df.shape)\n",
    "\n",
    "# 2) Drop columns with too many missing values\n",
    "df = drop_high_missing(df, threshold=0.30)\n",
    "print(\"After dropping columns:\", df.shape)\n",
    "\n",
    "# 3) Drop columns with correlation less then given\n",
    "if correlation_thresh > 0:\n",
    "    df = remove_low_correlation_features(df, target_col=target, \n",
    "                                        threshold=correlation_thresh,\n",
    "                                        output_dir=output_dir)\n",
    "    print(\"After removing low-correlation features:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f68be",
   "metadata": {},
   "source": [
    "### Vizualni prikaz zadržanih i uklonjenih atributa\n",
    "\n",
    "![Correlation Analysis](presentation%20files/correlation_analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918b28c",
   "metadata": {},
   "source": [
    "#### 4. Podela skupa podataka na trening, validacioni i test skup\n",
    "\n",
    "U ovom koraku delimo podatke na ulazne karakteristike (`X`) i ciljnu promenljivu (`y`), a zatim ih raspoređujemo u tri skupa:\n",
    "\n",
    "1. **Trening skup (train set)** – koristi se za treniranje modela.\n",
    "2. **Validacioni skup (val set)** – koristi se tokom treniranja za podešavanje hiperparametara i early stopping.\n",
    "3. **Test skup (test set)** – koristi se **samo na kraju** za evaluaciju konačnog modela.\n",
    "\n",
    "---\n",
    "\n",
    "#### Detalji:\n",
    "- Prvo izdvajamo test skup (`test_size`, 15%) iz celokupnog skupa podataka.\n",
    "- Preostali podaci (`X_temp`) se dele na trening i validacioni skup prema proporciji `val_size` u odnosu na ukupni skup.\n",
    "- Na kraju proveravamo veličine svih skupova da bismo se uverili da je podela ispravna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b43f13a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes -> train: 2050, val: 440, test: 440\n"
     ]
    }
   ],
   "source": [
    "from data.preprocessing import (\n",
    "    split_features_target\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "random_state = 42\n",
    "\n",
    "# 4) split X/y and then train/val/test (we must split BEFORE fitting preprocessors)\n",
    "X, y = split_features_target(df, target_col=target)\n",
    "# First split off test\n",
    "test_size = test_size\n",
    "val_size = val_size\n",
    "# Combine val+test fraction relative splitting\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")\n",
    "# Now split X_temp into train and val\n",
    "# val fraction of original = val_size -> fraction of X_temp = val_size / (1 - test_size)\n",
    "val_fraction_of_temp = val_size / (1.0 - test_size)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=val_fraction_of_temp, random_state=random_state\n",
    ")\n",
    "\n",
    "print(f\"Sizes -> train: {len(X_train)}, val: {len(X_val)}, test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d9d314",
   "metadata": {},
   "source": [
    "#### 5. Fitovanje predprocesora na trening skupu\n",
    "\n",
    "U ovom koraku pripremamo sve transformacije podataka koristeći **samo trening skup**, kako bismo izbegli curenje informacija iz validacionog ili test skupa.  \n",
    "\n",
    "- **Numeričke kolone**: nedostajući podaci se zamenjuju **medijanom**.  \n",
    "- **Kategorijske kolone**: nedostajuće vrednosti se zamenjuju tokenom `\"Missing\"`, a zatim se kolone enkodiraju koristeći **One-Hot Encoding**.  \n",
    "- **Skaliranje numeričkih kolona**: primenjuje se `StandardScaler` (mean=0, std=1) da bi mreža lakše učila.  \n",
    "- Rezultat je objekat `preprocessors` koji sadrži sve fitovane transformacije i liste kolona.\n",
    "\n",
    "#### 6. Transformacija skupova podataka\n",
    "\n",
    "Koristeći fitovane predprocesore, transformišemo sve skupove podataka (train, val, test):\n",
    "\n",
    "1. Numeričke kolone se impute-uju i skaliraju prema parametrima iz trening skupa.  \n",
    "2. Kategorijske kolone se enkodiraju i impute-uju `\"Missing\"` gde je potrebno.  \n",
    "3. Sve kolone se kombinuju u **jedan numpy niz** spreman za neuronsku mrežu (`X_train_np`, `X_val_np`, `X_test_np`).  \n",
    "\n",
    "- Rezultat: mreža dobija **numerički i normalizovan skup podataka**, spreman za treniranje i evaluaciju."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e92da493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric cols: 30, Categorical cols: 37\n"
     ]
    }
   ],
   "source": [
    "from data.preprocessing import (\n",
    "    build_preprocessors,\n",
    "    transform_dataframe,\n",
    ")\n",
    "\n",
    "# 5) Fit preprocessors on train only\n",
    "preprocessors = build_preprocessors(X_train)\n",
    "\n",
    "# 6) Transform datasets\n",
    "X_train_np = transform_dataframe(X_train, preprocessors)\n",
    "X_val_np = transform_dataframe(X_val, preprocessors)\n",
    "X_test_np = transform_dataframe(X_test, preprocessors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7826aa",
   "metadata": {},
   "source": [
    "#### 7. Primena PCA (Principal Component Analysis)\n",
    "\n",
    "U ovom koraku vršimo **redukciju dimenzionalnosti** koristeći PCA, što pomaže da se:\n",
    "- Smanji broj ulaznih atributa (feature-a) dok se zadržava što više informacija.  \n",
    "- Smanji rizik od **overfitting-a** i ubrza treniranje mreže.  \n",
    "\n",
    "**Postupak:**\n",
    "1. Kreiramo PCA objekat sa brojem komponenti `args.pca_components`.  \n",
    "2. Fitujemo PCA **samo na trening skupu** (`X_train_np`).  \n",
    "3. Transformišemo sve skupove (train, val, test) u novi prostor glavnih komponenti.  \n",
    "4. Novi dimenzionalitet podataka (`X_train_np.shape[1]`) odgovara broju PCA komponenti.  \n",
    "5. Vizualizujemo **doprinos originalnih atributa svakoj PCA komponenti** koristeći `plot_pca_feature_contributions`.  \n",
    "\n",
    "- Ovim korakom zadržavamo najinformativnije kombinacije atributa dok uklanjamo redundantne ili slabo relevantne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5283ac1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA applied: new feature dim 25\n",
      "PCA contribution plots saved to output\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from data.preprocessing import plot_pca_feature_contributions\n",
    "pca_components = 25\n",
    "\n",
    "# 7) PCA\n",
    "if pca_components and pca_components > 0:\n",
    "    pca = PCA(n_components=pca_components, random_state=random_state)\n",
    "    pca.fit(X_train_np)\n",
    "    X_train_np = pca.transform(X_train_np)\n",
    "    X_val_np = pca.transform(X_val_np)\n",
    "    X_test_np = pca.transform(X_test_np)\n",
    "    print(f\"PCA applied: new feature dim {X_train_np.shape[1]}\")\n",
    "else:\n",
    "    print(f\"No PCA. Feature dim: {X_train_np.shape[1]}\")\n",
    "\n",
    "all_feature_names = preprocessors[\"numeric_cols\"] + list(preprocessors[\"onehot_encoder\"].get_feature_names_out(preprocessors[\"categorical_cols\"]))\n",
    "plot_pca_feature_contributions(pca, all_feature_names, output_dir, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae6260",
   "metadata": {},
   "source": [
    "#### Analiza doprinosa atributa PCA komponentama\n",
    "\n",
    "Funkcija `plot_pca_feature_contributions` generiše **heatmap** koja prikazuje težine (loadings) svakog atributa u svakoj PCA komponenti:\n",
    "\n",
    "- **Redovi**: originalni atributi (npr. kvadratura, broj soba, godina izgradnje…).  \n",
    "- **Kolone**: PCA komponente (PC1, PC2, …).  \n",
    "- **Boje**: vrednost težine (loading) – crveno označava pozitivni doprinos, plavo negativni.  \n",
    "\n",
    "Parametar `top_n=10` prikazuje samo 10 atributa sa najvećim apsolutnim doprinosom po komponenti, čime se heatmap čini preglednijim.\n",
    "\n",
    "![PCA Loadings Heatmap](presentation%20files/pca_loadings_heatmap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888a1b6f",
   "metadata": {},
   "source": [
    "#### 8. Kreiranje DataLoader-a\n",
    "\n",
    "U ovom koraku pripremamo podatke za treniranje neuronske mreže koristeći **PyTorch DataLoader-e**:\n",
    "\n",
    "1. **TabularDataset**  \n",
    "   Kreiramo custom dataset za tabelarne podatke (`TabularDataset`), koji kombinuje ulazne karakteristike (`X_train_np`, `X_val_np`, `X_test_np`) i ciljne vrednosti (`y_train`, `y_val`, `y_test`).\n",
    "\n",
    "2. **DataLoader**  \n",
    "   - `train_loader` – koristi se za treniranje. Podešen sa `shuffle=True` da bi se podaci nasumično mešali svakom epohom.  \n",
    "   - `val_loader` i `test_loader` – koriste se za validaciju i testiranje, `shuffle=False` kako bi redosled podataka bio konzistentan.  \n",
    "   - `batch_size` određuje veličinu batch-a za treniranje i evaluaciju.\n",
    "\n",
    "DataLoader omogućava efikasno učitavanje podataka po batch-evima i olakšava treniranje neuronske mreže na velikim skupovima podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "349894cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import TabularDataset\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "train_ds = TabularDataset(X_train_np, y_train)\n",
    "val_ds = TabularDataset(X_val_np, y_val)\n",
    "test_ds = TabularDataset(X_test_np, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df2cf6",
   "metadata": {},
   "source": [
    "#### 9. Kreiranje modela\n",
    "\n",
    "U ovom koraku definišemo neuronsku mrežu za regresiju koristeći **PyTorch**:\n",
    "\n",
    "- **RegressionNet** je potpuno povezani (fully connected) mrežni model koji prima ulazne karakteristike i predviđa kontinualnu vrednost (cenu kuće).  \n",
    "- Model se sastoji od niza linearnih slojeva (`nn.Linear`) sa **ReLU** aktivacijom i opcionim **Dropout** slojevima za regularizaciju.  \n",
    "- Broj skrivenih slojeva i veličina svakog sloja definišu se listom `hidden_layers`, a `dropout` određuje verovatnoću isključivanja neurona tokom treninga.\n",
    "\n",
    "#### 10. Treniranje modela\n",
    "\n",
    "Model se trenira koristeći funkciju `train_model`:\n",
    "\n",
    "1. **Loss funkcija:** `MSELoss` (Mean Squared Error) meri prosečnu kvadratnu grešku između predviđenih i stvarnih vrednosti. \n",
    "2. **Optimizer:** `Adam` sa zadatim `learning rate` i opcionalnim `weight_decay` (L2 regularizacija).  \n",
    "3. **Early stopping:** prateći validacioni gubitak (`val_loss`), treniranje se prekida ako se gubitak ne poboljšava `patience` epohama.  \n",
    "4. **Prikupljanje statistika:** lista `train_losses` i `val_losses` čuva gubitke po epohi za kasniju vizualizaciju.  \n",
    "\n",
    "**Proces treniranja po epohi:**\n",
    "- Model se postavlja u `train` režim.\n",
    "- Svaki batch prolazi kroz mrežu (`forward pass`) i računa se gubitak.\n",
    "- Optimizator ažurira težine (`backward pass` + `optimizer.step()`).\n",
    "- Nakon prolaska kroz sve batch-eve, računa se prosečni gubitak za epohu.\n",
    "- Model se zatim evaluira na validacionom skupu (`eval` režim) da bi se pratila generalizacija.\n",
    "- Ako je validacioni gubitak najbolji do sada, model se čuva kao najbolji.\n",
    "- Ukoliko broj epoha odredjen parametrom **patience** nije pokazao napredovanje kod vrednosti validacione loss funckije - **primenjuje se early stopping**\n",
    "\n",
    "Na kraju, vraća se trenirani model sa najboljim težinama i liste gubitaka za treniranje i validaciju.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98f4acc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RegressionNet(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=25, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 025: train_loss=698344358.4624, val_loss=1058779447.8545\n",
      "Epoch 050: train_loss=489729998.2595, val_loss=871578612.3636\n",
      "Epoch 075: train_loss=382856448.3122, val_loss=919048960.0000\n",
      "Early stopping on epoch 78. Best val loss: 783799740.509091\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.neural_net import RegressionNet\n",
    "from training.training import (\n",
    "    train_model\n",
    ")\n",
    "hidden_layers = [512, 256, 128]\n",
    "dropout = 0.0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 500\n",
    "lr = 0.02\n",
    "patience = 20\n",
    "\n",
    "# 9) Create model\n",
    "input_dim = X_train_np.shape[1]\n",
    "model = RegressionNet(input_dim=input_dim, hidden_layers=hidden_layers, dropout=dropout)\n",
    "print(\"Model:\", model)\n",
    "\n",
    "# 10) Train\n",
    "model, train_losses, val_losses = train_model(\n",
    "    model, device, train_loader, val_loader,\n",
    "    epochs=epochs, lr=lr, patience=patience\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17accc73",
   "metadata": {},
   "source": [
    "#### 11. Vizualizacija treniranog gubitka (Loss)\n",
    "\n",
    "Na slici je prikazan tok gubitka (MSE) kroz epohe za **trening** i **validacioni** skup.  \n",
    "Možemo pratiti konvergenciju modela i eventualni overfitting.\n",
    "\n",
    "![Loss curve](presentation%20files/loss_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e90b22",
   "metadata": {},
   "source": [
    "#### 12. Evaluacija modela na test skupu\n",
    "\n",
    "Nakon treniranja, model je evaluiran na **test skupu** koji nije korišćen ni za treniranje ni za validaciju.  \n",
    "Koristimo standardne metrike za regresiju kako bismo procenili performanse modela:\n",
    "\n",
    "- **MSE (Mean Squared Error)** – 768,225,664  \n",
    "  Prosečna kvadratna greška između stvarnih i predviđenih vrednosti. Veća vrednost označava veća odstupanja pojedinačnih predikcija.\n",
    "\n",
    "- **RMSE (Root Mean Squared Error)** – 27,716.88  \n",
    "  Koren MSE, intuitivniji prikaz greške u istim jedinicama kao i ciljna promenljiva (`SalePrice`). Ovo znači da je prosečna greška modela oko $27,700 po kući.\n",
    "\n",
    "- **MAE (Mean Absolute Error)** – 18,201.21  \n",
    "  Prosečna apsolutna greška između predikcija i stvarnih vrednosti. Manja od RMSE, što sugeriše da ekstremni outlieri povećavaju kvadratnu grešku.\n",
    "\n",
    "- **R² (Coefficient of Determination)** – 0.90  \n",
    "  Ova vrednost pokazuje da model objašnjava oko 90% varijanse prodajne cene (`SalePrice`). To je veoma dobar rezultat, ukazujući na to da model precizno predviđa većinu promena u cenama kuća.\n",
    "\n",
    "**Zaključak:**  \n",
    "Model je postigao visoku tačnost i dobro generalizuje na nove podatke. Iako postoje pojedinačne greške koje utiču na MSE, ukupna sposobnost modela da predvidi cenu kuća je vrlo dobra, što potvrđuje visok R² skor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e584e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics:\n",
      "  MSE:  768225664.0000\n",
      "  RMSE: 27716.8848\n",
      "  MAE:  18201.2148\n",
      "  R²:   0.9000\n"
     ]
    }
   ],
   "source": [
    "from training.training import evaluate_model\n",
    "\n",
    "# 12) Evaluate on test\n",
    "test_metrics = evaluate_model(model, device, test_loader)\n",
    "print(\"Test metrics:\")\n",
    "print(f\"  MSE:  {test_metrics['mse']:.4f}\")\n",
    "print(f\"  RMSE: {test_metrics['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {test_metrics['mae']:.4f}\")\n",
    "print(f\"  R²:   {test_metrics['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820c5e74",
   "metadata": {},
   "source": [
    "#### 13. Scatter plot – Stvarne vs Predviđene vrednosti\n",
    "\n",
    "Na ovom scatter plot-u prikazujemo stvarne vrednosti cene kuća (`True SalePrice`) u odnosu na vrednosti predviđene modelom (`Predicted SalePrice`) na test skupu.\n",
    "\n",
    "- Svaka tačka predstavlja jednu kuću iz test skupa.\n",
    "- Isprekidana linija (y = x) prikazuje idealnu situaciju gde su predviđene cene kuća tačno jednake stvarnim cenama.\n",
    "- Tačke blizu linije označavaju tačne predikcije, dok tačke udaljene od linije predstavljaju greške u predikciji.\n",
    "\n",
    "Ovaj graf vizualno potvrđuje sposobnost modela da precizno predviđa cene kuća.\n",
    "\n",
    "![True vs Predicted](presentation%20files/true_vs_pred.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4ecd38",
   "metadata": {},
   "source": [
    "#### 14. Grafik važnosti komponenti\n",
    "\n",
    "U ovom koraku prikazujemo koliko svaka komponenta (npr. PCA komponenta) doprinosi modelu:\n",
    "- Visina svakog bara predstavlja prosečnu apsolutnu vrednost težina prve linearne sloja neuronske mreže za datu komponentu.\n",
    "- Komponente sa većim vrednostima imaju veći uticaj na predviđanje cena kuća.\n",
    "- Ovaj grafikon pomaže da identifikujemo koje komponente model najviše koristi i koje karakteristike podataka su najinformativnije.\n",
    "\n",
    "![True vs Predicted](presentation%20files/pca_component_importance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378f5f5",
   "metadata": {},
   "source": [
    "#### 15. Analiza grešaka i reziduala\n",
    "\n",
    "U ovom koraku vizualizujemo performanse modela kroz raspodelu grešaka:\n",
    "- Greške (errors) predstavljaju razliku između stvarne i predviđene cene kuće (true - pred).\n",
    "- Reziduali pokazuju koliko su predikcije odstupile od stvarnih vrednosti.\n",
    "- Ova analiza omogućava uvid u to da li model sistematski precenjuje ili potcenjuje cene, kao i da li postoje ekstremni odmaknuti slučajevi.\n",
    "\n",
    "Važno je uočiti da greške mogu biti uzorak **normalne raspodele**. To može da znači nekoliko stvari:\n",
    "1. **Model je dobro kalibrisan** – predikcije su, u proseku, tačne, i odstupanja su raspoređena simetrično oko nule.\n",
    "2. **Nema sistematske pristrasnosti** – model ne precenjuje ni potcenjuje konstantno; greške su slučajne i ne pokazuju obrazac.\n",
    "3. **Validnost klasičnih statističkih metoda** – normalna raspodela grešaka omogućava primenu metoda kao što su intervali poverenja, t-testovi i ANOVA, jer su osnovni preduslovi ispunjeni.\n",
    "4. **Predikcija varijanse** – većina grešaka je mala, a ekstremne vrednosti (outlajeri) su retke, što olakšava interpretaciju i procenu rizika.\n",
    "\n",
    "![True vs Predicted](presentation%20files/error_analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac99d6b7",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning (Grid search)\n",
    "\n",
    "Dodatan korak u razvoju projekta uključuje **grid search** - vršimo eksperimente sa različitim kombinacijama hiperparametara neuronske mreže:\n",
    "- **pca_componentts**: Broj glavnih komponenti nakon PCA redukcije dimenzionalnosti. Veći broj zadržava više informacija, manji broj smanjuje kompleksnost i vreme treniranja.\n",
    "- **lr**: Learning rate, odnosno, brzina kojom optimizator prilagođava težine mreže. Prevelika vrednost može dovesti do nestabilnog treniranja, premala usporava konvergenciju.\n",
    "- **hidden_layers**: Lista koja definiše broj i veličinu skrivenih slojeva u mreži. Više slojeva ili veći broj neurona može povećati kapacitet modela, ali i rizik od prenaučenosti.\n",
    "- **dropout**: Procenat neurona koji se nasumično isključuje tokom treniranja radi regularizacije. Pomaže u smanjenju prenaučenosti.\n",
    "- **batch_size**: Broj uzoraka koji se obrađuje u jednom prolazu optimizatora. Manji batch smanjuje memorijski zahtev i može dodati varijansu u treniranju, veći batch može ubrzati treniranje ali zahteva više memorije.\n",
    "\n",
    "Svaka kombinacija parametara predstavlja jedan eksperiment. Rezultati (MSE, RMSE, MAE, R²) se čuvaju i rangiraju po R². Omogućava identifikaciju najbolje konfiguracije za finalno treniranje modela.\n",
    "\n",
    "Modul `grid_search` omogućava automatsko testiranje različitih kombinacija hiperparametara nad modelom kroz parametre navedene u konfiguraciji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f86d77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_parameters():\n",
    "    \"\"\"\n",
    "    Define the hyperparameter grid for experimentation.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'pca_components': [20, 25, 30, 35, 40],\n",
    "        'lr': [0.001, 0.01, 0.02, 0.03],\n",
    "        'hidden_layers': [\n",
    "            [128, 64], \n",
    "            [256, 128, 64],\n",
    "            [512, 256, 128],\n",
    "            [512, 256, 128, 64]\n",
    "        ],\n",
    "        'dropout': [0.0, 0.1],\n",
    "        'batch_size': [32, 64, 96]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798b71e",
   "metadata": {},
   "source": [
    "### Rezultati eksperimenata i zaključci\n",
    "\n",
    "**Rezulati eksperimenata** rangirani su po vrednostima R² metrike. Rezultati svih eksperimenata (svih kombinacija) sadržani su u\n",
    "`grid_search_result.txt` zajedno sa vrednostima parametara korišćenih u okviru eksperimenta.\n",
    "Tri najbolje konfiguracije:\n",
    "- Rank 1 (R²: 0.9000):\n",
    "  - PCA Components: 25\n",
    "  - Learning Rate: 0.02\n",
    "  - Hidden Layers: [512, 256, 128]\n",
    "  - Dropout: 0.0\n",
    "  - Batch Size: 64\n",
    "  - RMSE: 27716.884765625\n",
    "  - MAE: 18201.21484375\n",
    "\n",
    "- Rank 2 (R²: 0.8990):\n",
    "  - PCA Components: 25\n",
    "  - Learning Rate: 0.03\n",
    "  - Hidden Layers: [512, 256, 128, 64]\n",
    "  - Dropout: 0.0\n",
    "  - Batch Size: 96\n",
    "  - RMSE: 27858.630859375\n",
    "  - MAE: 19455.927734375\n",
    "\n",
    "- Rank 3 (R²: 0.8979):\n",
    "  - Experiment ID: 451\n",
    "  - PCA Components: 40\n",
    "  - Learning Rate: 0.02\n",
    "  - Hidden Layers: [512, 256, 128, 64]\n",
    "  - Dropout: 0.0\n",
    "  - Batch Size: 32\n",
    "  - RMSE: 28004.130859375\n",
    "  - MAE: 18851.828125\n",
    "\n",
    "**Analiza i zaključci** na osnovu vrednosti parametara:\n",
    "- **PCA komponente**: Najbolje performanse su uglavnom postignute sa 25 PCA komponenti, što sugeriše da smanjenje dimenzionalnosti do ovog broja zadržava ključne informacije za predikciju. Veći broj komponenti (npr. 40) ne donosi značajno poboljšanje, što implicira da postoji višak informacija koji nije koristan za model.\n",
    "- **Learning rate**: Optimalni LR je oko 0.02, iako i 0.01 i 0.03 daju solidne rezultate.\n",
    "- **Hidden layers**: Najefikasnija arhitektura je [512, 256, 128] ili [512, 256, 128, 64], što pokazuje da mreža sa 3-4 skrivena sloja i postepeno smanjenim brojem neurona dobro modeluje kompleksnost podataka. Veće ili previše male mreže ne daju značajnu prednost.\n",
    "- **Dropout**: Najbolji modeli imaju dropout = 0.0, što sugeriše da regularizacija kroz dropout nije bila neophodna za ovaj dataset i mrežu (možda zbog dovoljno velikog broja primera i PCA smanjenja dimenzionalnosti).\n",
    "- **Batch size**: 64 je česta optimalna vrednost u modelima sa najboljim preformansama, ali i 32 i 96 daju slične rezultate. Ovo znači da model nije previše osetljiv na veličinu batch-a, što daje fleksibilnost pri treniranju.\n",
    "\n",
    "Model je stabilan: razlike između top 20 eksperimenata u R² su male (0.900 → 0.888), što znači da je mreža relativno robusna na promene hiperparametara. PCA, learning rate i broj slojeva su najvažniji parametri koji utiču na performanse. Dropout i batch size imaju manji uticaj u ovom slučaju."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
